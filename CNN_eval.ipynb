{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Using the model trained by *CNN_train_without_metadata* I classified all the given 3469 test images into one of 10 classes and gave me predictions in a csv named CNN_Classification in this notebook**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Importing all necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "XlS9GVLelZOD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "import glob"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checking if CUDA is avilable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLZmOW2OldVm",
        "outputId": "3a31ca10-e05d-4247-efc5-c811681b327f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch version = 2.5.0+cu118\n",
            "device = cuda\n"
          ]
        }
      ],
      "source": [
        "print(f'torch version = {torch.__version__}')\n",
        "#checking if CUDA is available\n",
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'device = {device}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Setting seed for reproducability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ogDHB4q1lkXt"
      },
      "outputs": [],
      "source": [
        "seed=42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Setting image and batch size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ySysuzXolnSy"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Defining test data path and test tranforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "VDrJaXlUlpmS"
      },
      "outputs": [],
      "source": [
        "DATASET_PATH = '.'  # Main dataset directory\n",
        "TRAIN_PATH = os.path.join(DATASET_PATH, 'train_images')\n",
        "TEST_PATH = os.path.join(DATASET_PATH, 'test_images')\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Defining class to prepare dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "llJ8Cxqel4Bc"
      },
      "outputs": [],
      "source": [
        "class PaddyLeafDatasetWithoutMetadata(Dataset):\n",
        "    def __init__(self, root_dir,transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        self.samples = []\n",
        "        for img_path in glob.glob(os.path.join(self.root_dir, '*.jpg')):\n",
        "            self.samples.append((img_path))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.samples[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image ,img_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Made test_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "shE5m3MMmY-O"
      },
      "outputs": [],
      "source": [
        "# Load test dataset (without metadata)\n",
        "test_dataset = PaddyLeafDatasetWithoutMetadata(\n",
        "    TEST_PATH,\n",
        "    transform=test_transforms,\n",
        ")\n",
        "\n",
        "test_loader=DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_m_glilEJMo",
        "outputId": "24fa2824-4f9d-40ad-8ee2-37734fe641f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3469\n"
          ]
        }
      ],
      "source": [
        "print(len(test_dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Defined Model architecture "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "8APQTcl_5wEA"
      },
      "outputs": [],
      "source": [
        "class MetadataAwareModel(nn.Module):\n",
        "    def __init__(self, base_model_name='resnet50', num_classes=10, num_varieties=1):\n",
        "        super(MetadataAwareModel, self).__init__()\n",
        "\n",
        "        # Initialize the CNN backbone\n",
        "        if base_model_name == 'resnet50':\n",
        "            self.backbone = models.resnet50(pretrained=True)\n",
        "            self.feature_dim = self.backbone.fc.in_features\n",
        "            self.backbone.fc = nn.Identity()  # Remove the final fully connected layer\n",
        "\n",
        "        elif base_model_name == 'efficientnet':\n",
        "            self.backbone = models.efficientnet_b0(pretrained=True)\n",
        "            self.feature_dim = self.backbone.classifier[1].in_features\n",
        "            self.backbone.classifier = nn.Identity()  # Remove the final classifier\n",
        "\n",
        "        elif base_model_name == 'densenet':\n",
        "            self.backbone = models.densenet121(pretrained=True)\n",
        "            self.feature_dim = self.backbone.classifier.in_features\n",
        "            self.backbone.classifier = nn.Identity()  # Remove the final classifier\n",
        "\n",
        "        # Layers for processing metadata\n",
        "        self.variety_fc = nn.Linear(num_varieties, 64)\n",
        "        self.age_fc = nn.Linear(1, 16)\n",
        "\n",
        "        # Combined feature dimension\n",
        "        combined_dim = self.feature_dim + 64 + 16\n",
        "\n",
        "        # Final classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(combined_dim, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, image, variety, age):\n",
        "        # Process image through the backbone\n",
        "        image_features = self.backbone(image)\n",
        "\n",
        "        # Process metadata\n",
        "        variety_features = torch.relu(self.variety_fc(variety))\n",
        "        age_features = torch.relu(self.age_fc(age))\n",
        "\n",
        "        # Concatenate all features\n",
        "        combined_features = torch.cat([image_features, variety_features, age_features], dim=1)\n",
        "\n",
        "        # Final classification\n",
        "        output = self.classifier(combined_features)\n",
        "\n",
        "        return output\n",
        "    \n",
        "\n",
        "\n",
        "class ImageOnlyModel(nn.Module):\n",
        "    def __init__(self, pretrained_model_path, base_model_name='densenet', num_classes=10):\n",
        "        super(ImageOnlyModel, self).__init__()\n",
        "\n",
        "        # Load the pre-trained model\n",
        "        pretrained_model = MetadataAwareModel(base_model_name=base_model_name, num_classes=num_classes, num_varieties=10)\n",
        "        pretrained_model.load_state_dict(torch.load(pretrained_model_path, map_location=device,weights_only=True))\n",
        "        \n",
        "        # Extract the CNN backbone from the pre-trained model\n",
        "        self.backbone = pretrained_model.backbone  # Keeping the pretrained feature extractor\n",
        "        self.feature_dim = pretrained_model.feature_dim  # Feature size from CNN\n",
        "\n",
        "        # New classifier (without metadata features)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(self.feature_dim, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, image):\n",
        "        # Extract image features\n",
        "        image_features = self.backbone(image)\n",
        "\n",
        "        # Pass through new classifier\n",
        "        output = self.classifier(image_features)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Created model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ah3lV0705_-o",
        "outputId": "b54544ea-b1c0-44d8-d4c8-68e5b1bb0d9f"
      },
      "outputs": [],
      "source": [
        "model_name = 'densenet'  # Choose from: 'resnet50', 'efficientnet', 'densenet'\n",
        "model=ImageOnlyModel('paddy_disease_densenet_with_metadata.pth',base_model_name=model_name,num_classes=10)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Loaded weights from .pth files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0RJj9oX6TyJ",
        "outputId": "e58a3f8a-5279-4820-d177-59bb029c7537"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "checkpoint_path = \"paddy_disease_densenet_without_metadata.pth\"\n",
        "model.load_state_dict(torch.load(checkpoint_path, map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu'),weights_only=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Defined a model which stores predictions in a DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "CjocsElT6-cX"
      },
      "outputs": [],
      "source": [
        "def prediction_model(model, dataloader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    image_names = []  # To store image names\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, paths in dataloader:\n",
        "          inputs = inputs.to(device)\n",
        "\n",
        "          outputs = model(inputs)\n",
        "          _, preds = torch.max(outputs, 1)\n",
        "\n",
        "          all_preds.extend(preds.cpu().numpy())\n",
        "          image_names.extend(paths)  # Collect image names\n",
        "\n",
        "    # Store predictions in a DataFrame\n",
        "    df = pd.DataFrame({\n",
        "        \"image_id\": [os.path.basename(p) for p in image_names],  # Extract only filename\n",
        "        \"label\": all_preds\n",
        "    })\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Doing predictions on test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tax4wp6E7NYW",
        "outputId": "57330b9c-96c8-4f9b-cbe7-2c297a122fc0"
      },
      "outputs": [],
      "source": [
        "predictions_df = prediction_model(model, test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prepared an encoding to class mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: 'bacterial_leaf_blight', 1: 'bacterial_leaf_streak', 2: 'bacterial_panicle_blight', 3: 'blast', 4: 'brown_spot', 5: 'dead_heart', 6: 'downy_mildew', 7: 'hispa', 8: 'normal', 9: 'tungro'}\n"
          ]
        }
      ],
      "source": [
        "class_to_idx={'bacterial_leaf_blight': 0, 'bacterial_leaf_streak': 1, 'bacterial_panicle_blight': 2, 'blast': 3, 'brown_spot': 4, 'dead_heart': 5, 'downy_mildew': 6, 'hispa': 7, 'normal': 8, 'tungro': 9}\n",
        "idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
        "\n",
        "print(idx_to_class)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Created a CSV with columns -> image_id and label , which is sorted according to image_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9IdSdia6BPiH"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_2861202/1122322357.py:2: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
            "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
            "A typical example is when you are setting values in a column of a DataFrame, like:\n",
            "\n",
            "df[\"col\"][row_indexer] = value\n",
            "\n",
            "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "  predictions_df['label'][i]=idx_to_class[predictions_df['label'][i]]\n",
            "/tmp/ipykernel_2861202/1122322357.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  predictions_df['label'][i]=idx_to_class[predictions_df['label'][i]]\n",
            "/tmp/ipykernel_2861202/1122322357.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'dead_heart' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  predictions_df['label'][i]=idx_to_class[predictions_df['label'][i]]\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "for i in range(len(predictions_df)):\n",
        "  predictions_df['label'][i]=idx_to_class[predictions_df['label'][i]]\n",
        "\n",
        "df_sorted = predictions_df.sort_values(by=\"image_id\")\n",
        "\n",
        "# Save the sorted DataFrame to a new CSV file\n",
        "df_sorted.to_csv(\"CNN_Classification.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
