{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imported all necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import timm\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if CUDA exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version = 2.5.0+cu118\n",
      "device = cuda\n"
     ]
    }
   ],
   "source": [
    "print(f'torch version = {torch.__version__}')\n",
    "#checking if CUDA is available\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'device = {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "setting seed for reproducability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "defined image and batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "defined test data path and transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '.'  # Main dataset directory\n",
    "TEST_PATH = os.path.join(DATASET_PATH, 'test_images')\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "defined a class to help with traing and validation set creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaddyLeafDatasetWithMetadata(Dataset):\n",
    "    def __init__(self, root_dir,transforms):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transforms\n",
    "\n",
    "        self.samples = []\n",
    "        for img_path in glob.glob(os.path.join(self.root_dir, '*.jpg')):\n",
    "            self.samples.append((img_path))\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.samples[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image ,img_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepared my test dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test dataset (without metadata)\n",
    "test_dataset = PaddyLeafDatasetWithMetadata(\n",
    "    TEST_PATH,\n",
    "    transforms=test_transforms,\n",
    ")\n",
    "\n",
    "test_loader=DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3469\n"
     ]
    }
   ],
   "source": [
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "defined my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeiTWithMetadata(nn.Module):\n",
    "    def __init__(self, num_classes, num_varieties):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Load Pretrained DeiT Model\n",
    "        self.vision_model = timm.create_model(\"deit_base_patch16_224\", pretrained=True, num_classes=0)  # No final classifier\n",
    "        deit_feature_dim = 768  # DeiT output size\n",
    "        \n",
    "        # Metadata Processing FCNN\n",
    "        self.variety_fc = nn.Linear(num_varieties, 64)  # Process variety metadata\n",
    "        self.age_fc = nn.Linear(1, 16)  # Process age metadata\n",
    "        \n",
    "        # Combined feature dimension\n",
    "        combined_dim = deit_feature_dim + 64 + 16  # 768 (DeiT) + 64 (variety) + 16 (age)\n",
    "        \n",
    "        # Final Classifier (Fusion of Image + Metadata)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(combined_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, image, variety, age):\n",
    "        # Extract features from DeiT\n",
    "        img_features = self.vision_model(image)  # (Batch, 768)\n",
    "        \n",
    "        # Process metadata\n",
    "        variety_features = torch.relu(self.variety_fc(variety))  # (Batch, 64)\n",
    "        age_features = torch.relu(self.age_fc(age))  # (Batch, 16)\n",
    "        \n",
    "        # Concatenate image & metadata features\n",
    "        combined_features = torch.cat((img_features, variety_features, age_features), dim=1)  # (Batch, 768+64+16)\n",
    "        \n",
    "        # Final classification\n",
    "        output = self.fc(combined_features)\n",
    "        return output\n",
    "    \n",
    "\n",
    "\n",
    "class DeiTWithoutMetadata(nn.Module):\n",
    "    def __init__(self, checkpoint_path,num_classes,):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Load Pretrained DeiT Model\n",
    "        pretrained_model = DeiTWithMetadata(num_classes=num_classes, num_varieties=10)\n",
    "        pretrained_model.load_state_dict(torch.load(checkpoint_path, map_location=device,weights_only=True))\n",
    "\n",
    "        self.vision_model = pretrained_model.vision_model\n",
    "        deit_feature_dim = 768  # DeiT output size\n",
    "        \n",
    "        # Final Classifier (Fusion of Image + Metadata)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(deit_feature_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, image):\n",
    "        # Extract features from DeiT\n",
    "        img_features = self.vision_model(image)  # (Batch, 768)\n",
    "        \n",
    "        \n",
    "        # Final classification\n",
    "        output = self.fc(img_features)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=DeiTWithoutMetadata('paddy_disease_transformer_with_metadata.pth',num_classes=10)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loaded weights for model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = \"paddy_disease_transformer_without_metadata.pth\"\n",
    "model.load_state_dict(torch.load(checkpoint_path, map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu'),weights_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "defined a function which predicts my labels and returns a dataframe with columns - image_id and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_model(model, dataloader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    image_names = []  # To store image names\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, paths in dataloader:\n",
    "          inputs = inputs.to(device)\n",
    "\n",
    "          outputs = model(inputs)\n",
    "          _, preds = torch.max(outputs, 1)\n",
    "\n",
    "          all_preds.extend(preds.cpu().numpy())\n",
    "          image_names.extend(paths)  # Collect image names\n",
    "\n",
    "    # Store predictions in a DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        \"image_id\": [os.path.basename(p) for p in image_names],  # Extract only filename\n",
    "        \"label\": all_preds\n",
    "    })\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "did the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = prediction_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "created a dictionary to store mappings from class id to label name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'bacterial_leaf_blight', 1: 'bacterial_leaf_streak', 2: 'bacterial_panicle_blight', 3: 'blast', 4: 'brown_spot', 5: 'dead_heart', 6: 'downy_mildew', 7: 'hispa', 8: 'normal', 9: 'tungro'}\n"
     ]
    }
   ],
   "source": [
    "class_to_idx={'bacterial_leaf_blight': 0, 'bacterial_leaf_streak': 1, 'bacterial_panicle_blight': 2, 'blast': 3, 'brown_spot': 4, 'dead_heart': 5, 'downy_mildew': 6, 'hispa': 7, 'normal': 8, 'tungro': 9}\n",
    "idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
    "\n",
    "print(idx_to_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stored the predicteions in a dataframe with columns - image_id and label, sorted according to image_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2861691/2967693036.py:2: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  predictions_df['label'][i]=idx_to_class[predictions_df['label'][i]]\n",
      "/tmp/ipykernel_2861691/2967693036.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  predictions_df['label'][i]=idx_to_class[predictions_df['label'][i]]\n",
      "/tmp/ipykernel_2861691/2967693036.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'blast' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  predictions_df['label'][i]=idx_to_class[predictions_df['label'][i]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(predictions_df)):\n",
    "  predictions_df['label'][i]=idx_to_class[predictions_df['label'][i]]\n",
    "\n",
    "df_sorted = predictions_df.sort_values(by=\"image_id\")\n",
    "\n",
    "# Save the sorted DataFrame to a new CSV file\n",
    "df_sorted.to_csv(\"Transformer_Classification.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
